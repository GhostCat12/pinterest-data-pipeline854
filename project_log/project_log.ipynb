{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a  new conda environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n pinterest_conda_env\n",
    "conda activate pinterest_conda_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installed any libraries required to run the user_posting_emulation.py using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install library_name\n",
    "conda install -c conda-forge library_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an EC2 instance \n",
    "Grabbed the key-pair from the created ec2 instance details section on AWS, and saved inside a .pem file.    \n",
    "Followed instructions on AWS on how to connect to EC2 instance. Entering following code in CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh -i \"0a60b9a8a831-key-pair.pem\" ec2-user@ec2-34-207-200-90.compute-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing Kafka on the EC2 client \n",
    "First installed java and checked its version (java -version). Then downloaded and 'unzipped' kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo yum install java-1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://archive.apache.org/dist/kafka/2.8.1/kafka_2.12-2.8.1.tgz   # Grab the version of kafka to install\n",
    "tar -xzf kafka_2.12-2.8.1.tgz                                           # To 'unzip' or 'untar' the file \n",
    "rm kafka_2.12-2.8.1.tgz                                                 # Remove the compressed file, keeping only uncompressed version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing IAM MSK authentication package on client EC2 machine.\n",
    "Inside the Kafka installation folder and then in the libs folder.  \n",
    "Downloaded the IAM MSK authentication package from Github, using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd kafka_2.12-2.8.1/\n",
    "cd libs\n",
    "wget https://github.com/aws/aws-msk-iam-auth/releases/download/v1.1.5/aws-msk-iam-auth-1.1.5-all.jar  # Download msk iam authentication file\n",
    "export CLASSPATH=/home/ec2-user/kafka_2.12-2.8.1/libs/aws-msk-iam-auth-1.1.5-all.jar # Set class path environment variable for MSK authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added above classpath environment variable to bashrc file to maintain across ec2 sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nano /home/ec2-user/.bashrc\n",
    "source ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/home/mhash/pinterest_data_pipeline_project/project_log/nano_bashrc_20231211.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo $CLASSPATH                          # To test, should return class path in configured correctly /home/ec2-user/kafka_2.12-2.8.1/libs/aws-msk-iam-auth-1.1.5-all.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### To assume the \\<UserId\\>-ec2-access-role, which contains the necessary permissions to authenticate the MSK cluster\n",
    "    \n",
    "IAM console > Roles > \\<UserId\\>-ec2-access-role      \n",
    "- copy ARN      \n",
    "\n",
    "Trust relationships tab > Edit trust policy > Add a principal       \n",
    "- Selected IAM roles as the Principal type , Replace ARN with the \\<UserId\\>-ec2-access-role ARN copied from ec2-access-role.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Kafka client to use AWS IAM\n",
    "modify client.properties file inside kafka_folder/bin directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd kafka_2.12-2.8.1/\n",
    "cd bin\n",
    "nano client.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/aws/aws-msk-iam-auth instructions on configuring a Kafka client to use AWS IAM with AWS_MSK_IAM mechanism\n",
    "\n",
    "# Sets up TLS (Transport Layer Security) for encryption (cryptographic protocol) and SASL (Simple Authentication and Security Layer) for authN (framework for authentication and data security in Internet protocols).\n",
    "security.protocol = SASL_SSL\n",
    "\n",
    "# Identifies the SASL mechanism to use.\n",
    "sasl.mechanism = AWS_MSK_IAM\n",
    "\n",
    "# Binds SASL client implementation.\n",
    "sasl.jaas.config = software.amazon.msk.auth.iam.IAMLoginModule required awsRoleArn=\"arn:aws:iam::584739742957:role/0a60b9a8a831-ec2-access-role\";\n",
    "\n",
    "# Encapsulates constructing a SigV4 signature based on extracted credentials.\n",
    "# The SASL client bound by \"sasl.jaas.config\" invokes this class.\n",
    "sasl.client.callback.handler.class = software.amazon.msk.auth.iam.IAMClientCallbackHandler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Kafka Topics\n",
    "\n",
    "Using the MSK Management Console to get cluster information\n",
    "Amazon MSK > pinterest-msk-cluster > View client information and save:  \n",
    "- Bootstrap servers Private endpoint (single-VPC)\n",
    "- Plaintext Apache Zookeeper connection string  \n",
    "\n",
    "topic names: \n",
    "- 0a60b9a8a831.pin for the Pinterest posts data\n",
    "- 0a60b9a8a831.geo for the post geolocation data\n",
    "- 0a60b9a8a831.user for the post user data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "./kafka-topics.sh --bootstrap-server b-1.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098 --command-config client.properties --create --topic 0a60b9a8a831.pin\n",
    "./kafka-topics.sh --bootstrap-server b-2.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098 --command-config client.properties --create --topic 0a60b9a8a831.geo\n",
    "./kafka-topics.sh --bootstrap-server b-3.pinterestmskcluster.w8g8jt.c12.kafka.us-east-1.amazonaws.com:9098 --command-config client.properties --create --topic 0a60b9a8a831.user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting the MSK cluster to an S3 bucket.    \n",
    "The s3 bucket our data will be saved in is user-0a60b9a8a831-bucket (IAM role already set up to write to s3 bucket )\n",
    "\n",
    "first Download confluent.io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume admin user privileges\n",
    "sudo -u ec2-user -i \n",
    "\n",
    "# create directory where we will save our connector \n",
    "mkdir kafka-connect-s3 && cd kafka-connect-s3 \n",
    "\n",
    "# download connector from Confluent\n",
    "wget https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3/versions/10.0.3/confluentinc-kafka-connect-s3-10.0.3.zip \n",
    "\n",
    "# copy connector to S3 bucket \n",
    "aws s3 cp ./confluentinc-kafka-connect-s3-10.0.3.zip s3://user-0a60b9a8a831-bucket/kafka-connect-s3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created custom plugin in the MSK Connect console   \n",
    "MSK console > MSK Connect section  > Custom plugins > Create custom plugin.\n",
    "Choose bucket where Confluent connector ZIP file is (s3://user-0a60b9a8a831-bucket/kafka-connect-s3/confluentinc-kafka-connect-s3-10.0.3.zip). Name plugin 0a60b9a8a831-plugin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a connector in MSK connect using custom plugin    \n",
    " \n",
    "MSK connect > Customised plugins > choose 0a60b9a8a831-plugin > Create connector >\n",
    "created a connector with the following \n",
    "Connector name : 0a60b9a8a831-connector\n",
    "Description â€“ optional : N/A\n",
    "\n",
    "Specifically your bucket name should be user-<your_UserId>-bucket\n",
    "topics.regex field in the connector configuration. Make sure it has the following structure: <your_UserId>.*. \n",
    "choose the IAM role used for authentication to the MSK cluster in the Access permissions tab. Remember the role has the following format <your_UserId>-ec2-access-role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
